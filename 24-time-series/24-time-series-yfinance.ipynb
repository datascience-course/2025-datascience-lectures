{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science \n",
    "# Lecture 24: Temporal data analysis and applications to stock analysis\n",
    "*COMP 5360 / MATH 4100, University of Utah, http://datasciencecourse.net/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we'll cover \n",
    "* temporal data analysis \n",
    "* importing stock data using the pandas_datareader python package \n",
    "* visualizing time series \n",
    "* rolling means\n",
    "* time-domain vs frequency-domain analysis \n",
    "\n",
    "Parts of this lecture were adapted from a [previous lecture by *Curtis Miller*](https://github.com/datascience-course/2019-datascience-lectures/tree/master/08-time-series) \n",
    "and a [lecture on Time Series and Spectral Analysis by James Holland Jones](http://web.stanford.edu/class/earthsys214/notes/series.html). \n",
    "\n",
    "Further reading: \n",
    "+ Yves Hilpisch, Python for Finance, O'Reilly, (2014) [link](http://proquest.safaribooksonline.com.ezproxy.lib.utah.edu/book/programming/python/9781491945360).\n",
    "\n",
    "For a more complete treatment, take Math 5075 (Time Series Analysis). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal data analysis\n",
    "\n",
    "A *time series* is a series of data points indexed by time, $x_i = x(t_i)$, for $i=1,\\ldots,n$. Examples frequently occur in \n",
    "* weather forecasting, \n",
    "* mathematical finance (stocks),\n",
    "* electricity demand in a power grid, \n",
    "* keystrokes on a computer, and \n",
    "* any applied science and engineering which involves temporal measurements\n",
    "\n",
    "*Temporal data analysis* or *time series analysis* is just the study of such data. \n",
    "\n",
    "As a first example of time series data, we'll consider stocks and *mathematical finance*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Mathematical finance \n",
    "\n",
    "Prior to the 1980s, banking and finance were well-known for being \"boring\"; investment banking was distinct from commercial banking and the primary role of the industry was handling \"simple\" (at least in comparison to today) financial instruments, such as loans. Deregulation under the Regan administration, coupled with an influx of mathematics and computing power have transformed the industry from the \"boring\" business of banking to what it is today. \n",
    "\n",
    "* Advanced mathematics, such as analysis of the [Black-Scholes model](https://en.wikipedia.org/wiki/Black%E2%80%93Scholes_model), is now essential to finance. \n",
    "* Algorithms are now responsible for making split-second decisions. In fact, [the speed at which light travels is a limitation when designing trading systems](http://www.nature.com/news/physics-in-finance-trading-at-the-speed-of-light-1.16872). \n",
    "* [Machine learning and data mining techniques are popular](http://www.ft.com/cms/s/0/9278d1b6-1e02-11e6-b286-cddde55ca122.html#axzz4G8daZxcl) in the financial sector. For example, **high-frequency trading (HFT)** is a branch of algorithmic trading where computers make thousands of trades in short periods of time, engaging in complex strategies such as statistical arbitrage and market making. HFT was responsible for phenomena such as the [2010 flash crash](https://en.wikipedia.org/wiki/2010_Flash_Crash) and a [2013 flash crash](http://money.cnn.com/2013/04/24/investing/twitter-flash-crash/) prompted by a hacked [Associated Press tweet](http://money.cnn.com/2013/04/23/technology/security/ap-twitter-hacked/index.html?iid=EL) about an attack on the White House."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports and setup\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "from scipy.signal import periodogram\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting and Visualizing Stock Data\n",
    "\n",
    "As described [here](https://yfinance-python.org/reference/index.html), the yfinance package provides easy access to Yahoo! Financeâ€™s API to retrieve market data. It includes classes and functions for downloading historical market data, accessing ticker information, managing cache, and more.\n",
    "\n",
    "The following are the publicly available classes, and functions exposed by the yfinance package:\n",
    "\n",
    "    Ticker: Class for accessing single ticker data.\n",
    "    Tickers: Class for handling multiple tickers.\n",
    "    Market: Class for accessing market summary.\n",
    "    download: Function to download market data for multiple tickers.\n",
    "    Search: Class for accessing search results.\n",
    "    Sector: Domain class for accessing sector information.\n",
    "    Industry: Domain class for accessing industry information.\n",
    "    Market: Class for accessing market status & summary.\n",
    "    EquityQuery: Class to build equity query filters.\n",
    "    FundQuery: Class to build fund query filters.\n",
    "    screen: Run equity/fund queries.\n",
    "    enable_debug_mode: Function to enable debug mode for logging.\n",
    "    set_tz_cache_location: Function to set the timezone cache location.\n",
    "\n",
    "Note there are various sources for financial date (yahoo, fred, iex...), and pandas_datareader also has many ways to access this type of data. In this lecture we will primarily use the download function from yfinance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2016, 1, 29)\n",
    "end = datetime(2023, 1, 29)\n",
    "ticker = 'AAPL'\n",
    "\n",
    "AAPL = yf.download(ticker, start, end)\n",
    "print(type(AAPL))\n",
    "print(AAPL.tail())\n",
    "print(AAPL.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this data mean? \n",
    "* **high** is the highest price of the stock on that trading day, \n",
    "* **low** the lowest price of the stock on that trading day, \n",
    "* **open** is the price of the stock at the beginning of the trading day (it need not be the closing price of the previous trading day)\n",
    "* **close** the price of the stock at closing time\n",
    "* **volume** indicates how many stocks were traded \n",
    "\n",
    "### Visualizing Stock Data\n",
    "\n",
    "Now that we have stock data we can visualize it using the `matplotlib` package, called using a convenience method, `plot()` in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL[\"Close\"].plot(grid = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting multiple stocks together\n",
    "\n",
    "For a variety of reasons, we may wish to plot multiple financial instruments together including:\n",
    "* we may want to compare stocks\n",
    "* compare them to the market or other securities such as [exchange-traded funds (ETFs)](https://en.wikipedia.org/wiki/Exchange-traded_fund).\n",
    "\n",
    "Here, we plot the adjusted close for several stocks together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSFT = yf.download('MSFT', start, end)\n",
    "GOOG = yf.download('GOOG', start, end)\n",
    "# Below I create a DataFrame consisting of the closing price of these stocks, first by making a list of these objects and using the join method\n",
    "close = pd.DataFrame({ \"AAPL\": AAPL['Close', 'AAPL'], \"MSFT\": MSFT['Close', 'MSFT'], \"GOOG\": GOOG['Close', 'GOOG']})\n",
    "close.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close.plot(grid = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Why is this plot difficult to read?\n",
    "\n",
    "It plots the *absolute price* of stocks with time. While absolute price is important, frequently we are more concerned about the *relative change* of an asset rather than its absolute price. Also, Microsoft stock is more expensive than Apple or Google stock, and this difference makes Apple and Google stock appear less volatile than they truly are (that is, their price appears not to vary as much with time).\n",
    "\n",
    "One solution is to use two different scales when plotting the data; one scale will be used by Apple and Microsoft stocks, and the other by Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close.plot(secondary_y = [\"AAPL\", \"MSFT\"], grid = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, this solution clearly has limitations. We only have two sides of the plot to add more labels! \n",
    "\n",
    "A \"better\" solution is to plot the information we actually want. One option is to plot the *stock returns since the beginning of the period of interest*:\n",
    "\n",
    "$$\n",
    "\\text{return}_{t,0} = \\frac{\\text{price}_t}{\\text{price}_0}\n",
    "$$\n",
    "\n",
    "This requires transforming the data, which we do using a *lambda function*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.apply(arg) will apply the function arg to each column in df, and return a DataFrame with the result\n",
    "# Recall that lambda x is an anonymous function accepting parameter x; in this case, x will be a pandas Series object\n",
    "stock_return = close.apply(lambda x: x / x[0])\n",
    "stock_return.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_return.plot(grid = True).axhline(y = 1, color = \"black\", lw = 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a much more useful plot! Note: \n",
    "* We can now see how profitable each stock was since the beginning of the period. \n",
    "* Furthermore, we see that these stocks are highly correlated; they generally move in the same direction, a fact that was difficult to see in the other charts.\n",
    "\n",
    "Alternatively, we could plot the change of each stock per day. One way to do so would be to use the *percentage increase of a stock*:\n",
    "$$\n",
    "\\text{increase}_t = \\frac{\\text{price}_{t} - \\text{price}_{t-1}}{\\text{price}_t}\n",
    "$$\n",
    "\n",
    "or the *log difference*.\n",
    "\n",
    "$$\n",
    "\\text{change}_t = \\log\\left( \\frac{\\text{price}_{t}}{\\text{price}_{t - 1}} \\right) = \\log(\\text{price}_{t}) - \\log(\\text{price}_{t - 1})\n",
    "$$\n",
    "\n",
    "Here, $\\log$ is the natural log. Log difference has a desirable property: the sum of the log differences can be interpreted as the log total change (as a percentage) over the period summed. Log differences also more cleanly correspond to how stock prices are modeled in continuous time.\n",
    "\n",
    "We can obtain and plot the log differences of the data as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_change = close.apply(lambda x: np.log(x) - np.log(x.shift(1))) # shift moves dates back by 1.\n",
    "stock_change.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_change.plot(grid = True).axhline(y = 0, color = \"black\", lw = 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you prefer to plot stock return or log difference? \n",
    "\n",
    "* Looking at returns since the beginning of the period make the overall trend of the securities apparent. \n",
    "* Log difference, however, emphasizes changes between days. \n",
    "\n",
    "### Comparing stocks to the overall market \n",
    "\n",
    "We often want to compare the performance of stocks to the performance of the overall market. \n",
    "[SPY](https://finance.yahoo.com/quote/SPY/) is the ticker symbol for the SPDR S&P 500 exchange-traded mutual fund (ETF), which is a fund that has roughly the stocks in the [S&P 500 stock index](https://finance.yahoo.com/quote/%5EGSPC?p=^GSPC). \n",
    "This serves as one measure for the overal market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPY = yf.download('SPY', start, end)\n",
    "SPY.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close['SPY'] = SPY['Close','SPY']\n",
    "close.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_return['SPY'] = close[['SPY']].apply(lambda x: x / x[0])\n",
    "stock_return.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_return.plot(grid = True).axhline(y = 1, color = \"black\", lw = 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_change['SPY'] = close[['SPY']].apply(lambda x: np.log(x) - np.log(x.shift(1))) # shift moves dates back by 1.\n",
    "stock_change.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_change.plot(grid = True).axhline(y = 0, color = \"black\", lw = 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Averages\n",
    "\n",
    "For a time series $x_t$, the *$q$-day moving average at time $t$*, denoted $MA^q_t$, is the average of $x_t$ over the past $q$ days, \n",
    "$$\n",
    "MA^q_t = \\frac{1}{q} \\sum_{i = 0}^{q-1} x_{t - i}\n",
    "$$\n",
    "\n",
    "The [`rolling`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rolling.html) function in Pandas provides functionality for computing moving averages. We'll use it to create a 20-day moving average for Apple stock data and plot it alongside the stock price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "AAPL[\"20d\",\"AAPL\"] = AAPL[\"Close\",\"AAPL\"].rolling(window = 20, center = False).mean()\n",
    "AAPL.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how late the rolling average begins. It cannot be computed until twenty days have passed. Note that this becomes more severe for slower moving averages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL[[\"Close\", \"20d\"]].tail(300).plot(grid = True); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the moving averages \"smooths\" the time series. This can sometimes make it easier to identify trends. The larger $q$, the less responsive a moving average is to fast fluctuations in the series $x_t$. \n",
    "So, if these fast fluctuations are considered \"noise\", a moving average will identify the \"signal\". \n",
    "* *Fast moving averages* have smaller $q$ and more closely follow the time series. \n",
    "* *Slow moving averages* have larger $q$ and respond less to the fluctuations of the stock.\n",
    "\n",
    "Let's compare the 20-day, 50-day, and 200-day moving averages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "AAPL[\"50d\",\"AAPL\"] = AAPL[\"Close\",\"AAPL\"].rolling(window = 50, center = False).mean()\n",
    "AAPL[\"200d\",\"AAPL\"] = AAPL[\"Close\",\"AAPL\"].rolling(window = 200, center = False).mean()\n",
    "\n",
    "AAPL[[\"Close\", \"20d\", \"50d\", \"200d\"]].tail(500).plot(grid = True); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 20-day moving average is the most sensitive to fluctuations, while the 200-day moving average is the least sensitive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trading strategies and backtesting \n",
    "\n",
    "\n",
    "**Trading** is the practice of buying and selling financial assets for the purpose of making a profit. Traders develop **trading strategies** that a computer can use to make trades. Sometimes, these can be very complicated, but other times traders make decisions based on finding patterns or trends in charts. \n",
    "\n",
    "One example is called the [moving average crossover strategy](http://www.investopedia.com/university/movingaverage/movingaverages4.asp). \n",
    "This strategy is based on two moving averages, a \"fast\" one and a \"slow\" one. The strategy is:\n",
    "\n",
    "* Trade the asset when the fast moving average crosses over the slow moving average.\n",
    "* Exit the trade when the fast moving average crosses over the slow moving average again.\n",
    "\n",
    "A trade will be prompted when the fast moving average crosses from below to above the slow moving average, and the trade will be exited when the fast moving average crosses below the slow moving average later.\n",
    "\n",
    "This is the outline of a complete strategy and we already have the tools to get a computer to automatically implement the strategy.\n",
    "\n",
    "But before we decide if we want to use it, we should first evaluate the quality of the strategy. The usual means for doing this is called **backtesting**, which is looking at how profitable the strategy is on historical data. \n",
    "\n",
    "You could now write python code that could implement and backtest a trading strategy. There are also lots of python packages for this:  \n",
    "* [**pyfolio**](https://quantopian.github.io/pyfolio/) (for analytics)\n",
    "* [**zipline**](http://www.zipline.io/beginner-tutorial.html) (for backtesting and algorithmic trading), and \n",
    "* [**backtrader**](https://www.backtrader.com/) (also for backtesting and trading). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-domain vs frequency-domain analysis  \n",
    "\n",
    "So far, we have thought about a time series $x(t)$ in the \"time domain\". But, for some time series, it is easier to describe them in terms of the \"frequency domain\".\n",
    "\n",
    "For example, a good way to describe the function  \n",
    "$$\n",
    "x(t) = \\cos\\left( 2 \\pi f t \\right)\n",
    "$$\n",
    "is as an oscillating function with frequency $f$ (or period $1/f$). \n",
    "\n",
    "According to [Fourier analysis](https://en.wikipedia.org/wiki/Fourier_transform), we can decompose any signal into its frequency components, \n",
    "$$\n",
    "x(t) = \\sum_{n=-\\infty}^\\infty \\hat{x}(n) \\ e^{2 \\pi i n t}\n",
    "\\qquad \\qquad t \\in [0,1] \n",
    "$$\n",
    "or \n",
    "$$\n",
    "x(t) = \\int_{-\\infty}^\\infty \\hat{x}(f) \\ e^{2 \\pi i f t} \\ df\n",
    "\\qquad \\qquad t \\in [-\\infty,\\infty]. \n",
    "$$\n",
    "\n",
    "The \n",
    "[*power spectral density* or *periodogram*](https://en.wikipedia.org/wiki/Spectral_density) \n",
    "$S_{xx}(f) \\approx |\\hat x(f) |^2$ \n",
    "of a time series $x(t)$ describes the distribution of power into the frequency components that compose that signal. \n",
    "\n",
    "There are lots of time-dependent signals that are periodic or at least some of the signal is periodic. Examples: \n",
    "* [sunspots](https://en.wikipedia.org/wiki/Sunspot) follow an 11 year cycle. So if $x(t)$ was a time series representing the \"strength\" of the sunspot, we would have that $|\\hat{x}(f)|^2$ would be large at $f = 1/11$. (Remember period = 1/frequency.)  \n",
    "* The temperature in SLC. Here, we can decompose the temperature into a part that is varying over the course of a year, the part that varies over the day, and the \"remaining\" part.\n",
    "* $\\ldots$\n",
    "\n",
    "\n",
    "We can compute the power spectral density using the scipy function \n",
    "[`periodogram`](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.signal.periodogram.html). \n",
    "\n",
    "To illustrate this, we'll follow the \n",
    "[course notes of James Holland Jones on Time Series and Spectral Analysis](http://web.stanford.edu/class/earthsys214/notes/series.html) \n",
    "and consider \n",
    "[historical measles data from New York City posted by Ben Bolker](https://ms.mcmaster.ca/~bolker/measdata.html). \n",
    "\n",
    "\n",
    "### Measles data\n",
    "\n",
    "We can download the monthly measles data from New York City between 1928 and 1964. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"nycmeas.dat\", sep=\" \", names=[\"date\",\"cases\"])\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cases\"].plot(grid = True); \n",
    "plt.show()\n",
    "plt.plot(df[\"date\"].tolist(), df[\"cases\"].tolist())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the plot, we observe that the series is very regular with \"periodically occuring\" spikes. It appears that approximately once a year, there is a significant measles outbreak. By computing the power spectrum, we can see which frequencies make up this time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = df[\"cases\"].values\n",
    "f, Pxx_den = periodogram(cases, fs=12, window=\"hamming\")\n",
    "\n",
    "plt.plot(f, Pxx_den);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are 12 months per year, we set the measurement frequency argument in `periodogram` as fs=12. \n",
    "\n",
    "Clearly, the dominant frequency in this signal is 1 year. Why? \n",
    "\n",
    "\n",
    "**Q:** Is it useful to look at the power spectrum of stock data? \n",
    "\n",
    "**Exercise:** try it for the Apple stock data over the previous 10 years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, Pxx_den = periodogram(AAPL['Close', 'AAPL'].values, fs=365, window=\"hamming\")\n",
    "\n",
    "plt.plot(f[:20], Pxx_den[:20]);"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
