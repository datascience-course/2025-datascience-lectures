{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Data Science \n",
    "# Activity for Lecture 16: Classification\n",
    "*COMP 5360 / MATH 4100, University of Utah, http://datasciencecourse.net/*\n",
    "\n",
    "Name:\n",
    "\n",
    "Email:\n",
    "\n",
    "UID:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Analysis of Penguins Dataset \n",
    "\n",
    "Recall the 'Penguins' dataset available [here](https://github.com/allisonhorst/palmerpenguins/blob/main/README.md) and also in seaborn. \n",
    "This dataset consists of various features of 344 penguins consisting of 3 different species. \n",
    "\n",
    "![](penguins.jpg)\n",
    "\n",
    "First import needed packages and the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
      "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
      "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
      "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
      "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
      "5  Adelie  Torgersen            39.3           20.6              190.0   \n",
      "\n",
      "   body_mass_g     sex  \n",
      "0       3750.0    Male  \n",
      "1       3800.0  Female  \n",
      "2       3250.0  Female  \n",
      "4       3450.0  Female  \n",
      "5       3650.0    Male  \n"
     ]
    }
   ],
   "source": [
    "# imports and setup\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import svm, metrics # Support vector machine\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Import data:\n",
    "penguins = sns.load_dataset(\"penguins\")\n",
    "penguins = penguins.dropna()\n",
    "print(penguins.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this activity we will use the four quantitative variables (bill_length_mm, bill_depth_mm, flipper_length_mm, and body_mass_g) to create a classifier of the penguins' species. We will explore both a kNN and svm classifier.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: A First kNN Model\n",
    "\n",
    "Create a k-nearest neighbor classifier to predict species; try to choose the $k>1$ which gives as high of an accuracy as possible on the full data set. Print the confusion matrix, the accuracy score, and report the value of $k$ which you used.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer goes here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: kNN with Cross Validation\n",
    "\n",
    "Now split your data into a training and testing dataset. Train your model on 70\\% of the data and use 30\\% for testing. Consider all the various kNN models corresponding to the following possible values of $k$: $[2,4,6,8,10,12,14,16,18,20]$. For each $k$, train a kNN classifier on the training data and report the accuracy on both the training and test data. Which value of $k$ gives the best model? Did you pick a different $k$ than in task 1?    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer goes here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: A First SVM Model\n",
    "\n",
    "Create an SVM classifier to predict species; try both a linear and rbf kernel and try to choose the $C$ which gives as high of an accuracy as possible on the full data set. Print the confusion matrix, the accuracy score, and report the value of $C$ which you used.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer goes here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Task 4: SVM with Cross Validation\n",
    "\n",
    "Now split your data into a training and testing dataset. Train your model on 70\\% of the data and use 30\\% for testing. Consider all the various SVM models corresponding to the following possible values of $C$: $[.001, .01, .1, 1, 2.5, 5, 10, 20, 40, 80]$ (use the kernel you found best in task 3). For each $C$, train an SVM classifier on the training data and report the accuracy on both the training and test data. Which value of $C$ gives the best model? Did you pick a different $C$ than in task 3?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# your code goes here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Your answer goes here:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Task 5 (Time Permitting): k-fold Cross Validation \n",
    "\n",
    "Revisit tasks 2 and 4 but this time use k-fold Cross Validation with 4 folds. For kNN, make a plot of $k$ versus mean accuracy across folds and for SVM make a plot of $C$ versus mean accuracy accross folds. Which model performs better, kNN or SVM? Did you observe a big difference in results when doing cross validation with a single train test split and doing k-fold cross validation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# your code goes here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Your answer goes here:**\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
